{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4_l46UCdLAe"
      },
      "source": [
        "## Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leWlJrHUpu8d",
        "outputId": "d231818f-12f3-497a-b730-f6b7664cb797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aL8S1wM6ckue"
      },
      "outputs": [],
      "source": [
        "# Librerias Básicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Anotaciones, clases, tipos\n",
        "from dataclasses import dataclass\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from typing import Dict, Iterable, List, Optional, Tuple\n",
        "\n",
        "# Encoders\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "\n",
        "# Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Evaluación\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9LQTFvhd-2h"
      },
      "source": [
        "## Configuración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nx5y9nRJeBq_"
      },
      "outputs": [],
      "source": [
        "# === VARIABLES DE CONFIGURACIÓN ===\n",
        "SEED = 42\n",
        "TARGET_COLUMN = \"RENDIMIENTO_GLOBAL\"\n",
        "DATA_PATH = Path(\"train.csv\")\n",
        "EXPORT_PATH = Path(\"processed_train.parquet\")\n",
        "PIPELINE_PATH = Path(\"preprocessing_pipeline.joblib\")\n",
        "\n",
        "# === COLUMNAS IDENTIFICADAS EN EL ANÁLISIS EXPLORATORIO ===\n",
        "\n",
        "# Columnas que no vamos a usar\n",
        "DROP_CANDIDATES = [\n",
        "    \"ID\",  # No hay señal predictiva\n",
        "    \"F_TIENEINTERNET.1\",  # Información duplicada de F_TIENEINTERNET\n",
        "    \"E_PRIVADO_LIBERTAD\",  # Varianza MUY baja (≈0.005%)\n",
        "]\n",
        "\n",
        "# Columnas con alta cardinalidad\n",
        "HIGH_CARDINALITY = [\n",
        "    \"E_PRGM_ACADEMICO\",  # Más de 900 categorías\n",
        "    \"E_PRGM_DEPARTAMENTO\",  # Más de 30 categorías\n",
        "]\n",
        "\n",
        "# Columnas con baja cardinalidad\n",
        "LOW_CARDINALITY = [\n",
        "    \"F_TIENEINTERNET\",\n",
        "    \"F_TIENECOMPUTADOR\",\n",
        "    \"F_TIENEAUTOMOVIL\",\n",
        "    \"F_TIENELAVADORA\",\n",
        "    \"E_PAGOMATRICULAPROPIO\",\n",
        "]\n",
        "\n",
        "# Mapeo para columnas ordinales\n",
        "ORDINAL_MAP = {\n",
        "    \"F_ESTRATOVIVIENDA\": [\n",
        "        \"Desconocido\",\n",
        "        \"Sin Estrato\",\n",
        "        \"Estrato 1\",\n",
        "        \"Estrato 2\",\n",
        "        \"Estrato 3\",\n",
        "        \"Estrato 4\",\n",
        "        \"Estrato 5\",\n",
        "        \"Estrato 6\",\n",
        "    ],\n",
        "    \"E_HORASSEMANATRABAJA\": [\n",
        "        \"Desconocido\",\n",
        "        \"0\",\n",
        "        \"Menos de 10 horas\",\n",
        "        \"Entre 11 y 20 horas\",\n",
        "        \"Entre 21 y 30 horas\",\n",
        "        \"Más de 30 horas\",\n",
        "    ],\n",
        "    \"E_VALORMATRICULAUNIVERSIDAD\": [\n",
        "        \"Desconocido\",\n",
        "        \"No pagó matrícula\",\n",
        "        \"Menos de 500 mil\",\n",
        "        \"Entre 500 mil y menos de 1 millón\",\n",
        "        \"Entre 1 millón y menos de 2.5 millones\",\n",
        "        \"Entre 2.5 millones y menos de 4 millones\",\n",
        "        \"Entre 4 millones y menos de 5.5 millones\",\n",
        "        \"Entre 5.5 millones y menos de 7 millones\",\n",
        "        \"Más de 7 millones\",\n",
        "    ],\n",
        "    \"F_EDUCACIONPADRE\": [\n",
        "        \"Desconocido\",\n",
        "        \"Ninguno\",\n",
        "        \"Primaria incompleta\",\n",
        "        \"Primaria completa\",\n",
        "        \"Secundaria (Bachillerato) incompleta\",\n",
        "        \"Secundaria (Bachillerato) completa\",\n",
        "        \"Técnica o tecnológica incompleta\",\n",
        "        \"Técnica o tecnológica completa\",\n",
        "        \"Educación profesional incompleta\",\n",
        "        \"Educación profesional completa\",\n",
        "        \"Postgrado\",\n",
        "        \"No Aplica\",\n",
        "        \"No sabe\",\n",
        "    ],\n",
        "    \"F_EDUCACIONMADRE\": [\n",
        "        \"Desconocido\",\n",
        "        \"Ninguno\",\n",
        "        \"Primaria incompleta\",\n",
        "        \"Primaria completa\",\n",
        "        \"Secundaria (Bachillerato) incompleta\",\n",
        "        \"Secundaria (Bachillerato) completa\",\n",
        "        \"Técnica o tecnológica incompleta\",\n",
        "        \"Técnica o tecnológica completa\",\n",
        "        \"Educación profesional incompleta\",\n",
        "        \"Educación profesional completa\",\n",
        "        \"Postgrado\",\n",
        "        \"No Aplica\",\n",
        "        \"No sabe\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Columnas numéricas\n",
        "NUMERIC_COLUMNS = [\n",
        "    \"PERIODO_ACADEMICO\",\n",
        "    \"INDICADOR_1\",\n",
        "    \"INDICADOR_2\",\n",
        "    \"INDICADOR_3\",\n",
        "    \"INDICADOR_4\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCFVUpV1oWxb"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVu5hKRHoWYj",
        "outputId": "7de360ec-22a7-4611-92c3-4c6e9b3073fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ./kaggle.json'\n",
            "udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip\n",
            "replace submission_example.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "os.environ[\"KAGGLE_CONFIG_DIR\"] = \".\"\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n",
        "!unzip udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fD-iMrWTxeNf"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path: Path = DATA_PATH) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path, encoding=\"latin-1\")\n",
        "    return df\n",
        "\n",
        "def profile_dataset(df: pd.DataFrame) -> Dict[str, object]:\n",
        "    summary = {\n",
        "        \"shape\": df.shape,\n",
        "        \"target_distribution\": df[TARGET_COLUMN].value_counts().to_dict(),\n",
        "        \"dtypes\": df.dtypes.astype(str).to_dict(),\n",
        "        \"missing_fraction\": df.isna().mean().sort_values(ascending=False).head(10).to_dict(),\n",
        "    }\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7UpnA5prR2W"
      },
      "source": [
        "## Clases de Ayuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piSFxIu8w1Xa"
      },
      "source": [
        "### Imputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NePcnSDEsOeU"
      },
      "outputs": [],
      "source": [
        "class DataFrameImputer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Rellenar datos faltantes, manteniendo la estructura DataFrame\n",
        "    con los nombres de las columnas.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, fill_value: str = \"Desconocido\") -> None:\n",
        "        self.fill_value = fill_value\n",
        "        self.columns_: Optional[List[str]] = None\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> \"DataFrameImputer\":\n",
        "        self.columns_ = list(X.columns) if hasattr(X, \"columns\") else None\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        if self.columns_ is None:\n",
        "            raise RuntimeError(\"Se debe llamar fit antes de transform.\")\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            X = pd.DataFrame(X, columns=self.columns_)\n",
        "        return X.fillna(self.fill_value)\n",
        "\n",
        "    def get_feature_names_out(self, input_features: Optional[List[str]] = None) -> np.ndarray:\n",
        "        \"\"\"Devolver nombre de los features/columnas para los transformers.\"\"\"\n",
        "        if input_features is not None:\n",
        "            return np.asarray(input_features, dtype=object)\n",
        "        if self.columns_ is None:\n",
        "            raise RuntimeError(\"Llamar fit antes de solicitar los nombres.\")\n",
        "        return np.asarray(self.columns_, dtype=object)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpcx8tXnwo6a"
      },
      "source": [
        "### Configuración de Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WNVgCj1ds3Pj"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class FeatureConfig:\n",
        "    \"\"\"Clase para almacenar la categorización de columnas\"\"\"\n",
        "\n",
        "    drop: List[str]\n",
        "    high_card: List[str]\n",
        "    low_card: List[str]\n",
        "    ordinal: List[str]\n",
        "    numeric: List[str]\n",
        "    ordinal_categories: List[List[str]]\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df: pd.DataFrame) -> \"FeatureConfig\":\n",
        "        available_columns = set(df.columns)\n",
        "        drop = [c for c in DROP_CANDIDATES if c in available_columns]\n",
        "        usable = available_columns - {TARGET_COLUMN}\n",
        "        high_card = [c for c in HIGH_CARDINALITY if c in usable]\n",
        "        low_card = [c for c in LOW_CARDINALITY if c in usable]\n",
        "        ordinal = [c for c in ORDINAL_MAP if c in usable]\n",
        "        numeric = [c for c in NUMERIC_COLUMNS if c in usable]\n",
        "        ordinal_categories = [ORDINAL_MAP[c] for c in ordinal]\n",
        "        return cls(drop, high_card, low_card, ordinal, numeric, ordinal_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z1uRHvhxsXo"
      },
      "source": [
        "## Pipeline de Preprocesamiento\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cg0fN_l4BEU"
      },
      "source": [
        "### Construcción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jmWUIKXsx2Ul"
      },
      "outputs": [],
      "source": [
        "def make_preprocessor(config: FeatureConfig, random_state: int = SEED) -> Pipeline:\n",
        "    \"\"\"\n",
        "    Construir el pipeline de preprocesamiento, con las transformaciones para\n",
        "    cada columna.\n",
        "    \"\"\"\n",
        "    transformers = []\n",
        "\n",
        "    # Para las columnas de alta cardinalidad:\n",
        "    # 1. Rellenamos datos vacíos manteniendo la estructura\n",
        "    # 2. Convertimos las categorías en números usando la media de RENDIMIENTO_GLOBAL\n",
        "    # 3. Agregamos este pipeline al conjunto de transformaciones\n",
        "    if config.high_card:\n",
        "        high_card_pipeline = Pipeline(\n",
        "            steps=[\n",
        "                (\"imputer\", DataFrameImputer(fill_value=\"Desconocido\")),\n",
        "                (\n",
        "                    \"encoder\",\n",
        "                    TargetEncoder(\n",
        "                        cols=config.high_card,\n",
        "                        smoothing=0.5,\n",
        "                        handle_unknown=\"value\",\n",
        "                        handle_missing=\"value\",\n",
        "                    ),\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        transformers.append((\"high_card\", high_card_pipeline, config.high_card))\n",
        "\n",
        "    # Para las columnas ordinales:\n",
        "    # 1. Rellenamos datos vacíos con \"Desconocido\"\n",
        "    # 2. Convierte las categorías en números, respetando el orden lógico\n",
        "    # 3. Agregamos este pipeline al conjunto de transformaciones\n",
        "    if config.ordinal:\n",
        "        ordinal_pipeline = Pipeline(\n",
        "            steps=[\n",
        "                (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Desconocido\")),\n",
        "                (\n",
        "                    \"encoder\",\n",
        "                    OrdinalEncoder(\n",
        "                        categories=config.ordinal_categories,\n",
        "                        dtype=float,\n",
        "                        handle_unknown=\"use_encoded_value\",\n",
        "                        unknown_value=-1,\n",
        "                    ),\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        transformers.append((\"ordinal\", ordinal_pipeline, config.ordinal))\n",
        "\n",
        "    # Para las columnas de baja cardinalidad:\n",
        "    # 1. Rellenamos datos vacíos con \"Desconocido\"\n",
        "    # 2. Convierte las categorías en columnas binarias\n",
        "    # 3. Agregamos este pipeline al conjunto de transformaciones\n",
        "    if config.low_card:\n",
        "        low_card_pipeline = Pipeline(\n",
        "            steps=[\n",
        "                (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Desconocido\")),\n",
        "                (\n",
        "                    \"encoder\",\n",
        "                    OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        transformers.append((\"one_hot\", low_card_pipeline, config.low_card))\n",
        "\n",
        "    # Para las columnas numéricas:\n",
        "    # 1. Rellenamos datos vacíos con la MEDIANA\n",
        "    # 2. Transformamos los valores para que tengan media 0 y desv. std 1\n",
        "    # 3. Agregamos este pipeline al conjunto de transformaciones\n",
        "    if config.numeric:\n",
        "        numeric_pipeline = Pipeline(\n",
        "            steps=[\n",
        "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                (\"scaler\", StandardScaler()),\n",
        "            ]\n",
        "        )\n",
        "        transformers.append((\"numeric\", numeric_pipeline, config.numeric))\n",
        "\n",
        "    column_transformer = ColumnTransformer(\n",
        "        transformers=transformers,\n",
        "        remainder=\"drop\",\n",
        "        verbose_feature_names_out=False,\n",
        "    )\n",
        "\n",
        "    preprocessing_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocess\", column_transformer),\n",
        "            (\"variance\", VarianceThreshold(threshold=1e-5)),\n",
        "        ]\n",
        "    )\n",
        "    return preprocessing_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSJkP_NrxV74"
      },
      "source": [
        "### Exportar Pipeline y Dataset preprocesado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UCxzLvX2xT_I"
      },
      "outputs": [],
      "source": [
        "def export_transformed_dataset(\n",
        "    df: pd.DataFrame,\n",
        "    config: FeatureConfig,\n",
        "    output_path: Path = EXPORT_PATH,\n",
        "    pipeline_path: Path = PIPELINE_PATH,\n",
        "    random_state: int = SEED,\n",
        ") -> None:\n",
        "    X = df.drop(columns=[TARGET_COLUMN] + config.drop, errors=\"ignore\")\n",
        "    y = df[TARGET_COLUMN]\n",
        "\n",
        "    preprocessing = make_preprocessor(config, random_state=random_state)\n",
        "    preprocessing.fit(X, y)\n",
        "\n",
        "    feature_names = preprocessing.named_steps[\"preprocess\"].get_feature_names_out()\n",
        "    mask = preprocessing.named_steps[\"variance\"].get_support()\n",
        "    selected_feature_names = feature_names[mask]\n",
        "    transformed = preprocessing.transform(X)\n",
        "\n",
        "    processed_df = pd.DataFrame(transformed, columns=selected_feature_names, index=df.index)\n",
        "    processed_df[TARGET_COLUMN] = y.values\n",
        "    processed_df.to_parquet(output_path, index=False)\n",
        "\n",
        "    joblib.dump(preprocessing, pipeline_path)\n",
        "\n",
        "    return processed_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvpRy2-zol9p",
        "outputId": "82b797bc-d4aa-411a-ab23-7215bfaac171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   E_PRGM_ACADEMICO  E_PRGM_DEPARTAMENTO  F_ESTRATOVIVIENDA  \\\n",
            "0          1.662742             1.458950                4.0   \n",
            "1          1.441590             1.481302                4.0   \n",
            "2          1.741652             1.458950                4.0   \n",
            "3          1.622211             1.404329                5.0   \n",
            "4          1.543373             1.407370                4.0   \n",
            "5          1.465016             1.407370                6.0   \n",
            "6          1.145641             1.657729                3.0   \n",
            "7          1.707842             1.458950                3.0   \n",
            "8          1.396686             1.481302                2.0   \n",
            "9          1.622211             1.407370                6.0   \n",
            "\n",
            "   E_HORASSEMANATRABAJA  E_VALORMATRICULAUNIVERSIDAD  F_EDUCACIONPADRE  \\\n",
            "0                   2.0                          7.0              -1.0   \n",
            "1                   1.0                          5.0              -1.0   \n",
            "2                  -1.0                          5.0               5.0   \n",
            "3                   1.0                          6.0              12.0   \n",
            "4                   4.0                          5.0               3.0   \n",
            "5                   2.0                         -1.0              -1.0   \n",
            "6                   4.0                          5.0              -1.0   \n",
            "7                   3.0                         -1.0               2.0   \n",
            "8                   2.0                          7.0               5.0   \n",
            "9                  -1.0                          5.0              10.0   \n",
            "\n",
            "   F_EDUCACIONMADRE  F_TIENEINTERNET_Desconocido  F_TIENEINTERNET_No  \\\n",
            "0              10.0                          0.0                 0.0   \n",
            "1              -1.0                          0.0                 1.0   \n",
            "2               5.0                          0.0                 0.0   \n",
            "3               5.0                          0.0                 0.0   \n",
            "4               3.0                          0.0                 0.0   \n",
            "5               5.0                          0.0                 0.0   \n",
            "6              -1.0                          0.0                 0.0   \n",
            "7               4.0                          0.0                 0.0   \n",
            "8              -1.0                          0.0                 0.0   \n",
            "9              10.0                          0.0                 0.0   \n",
            "\n",
            "   F_TIENEINTERNET_Si  ...  F_TIENELAVADORA_Si  \\\n",
            "0                 1.0  ...                 1.0   \n",
            "1                 0.0  ...                 1.0   \n",
            "2                 1.0  ...                 1.0   \n",
            "3                 1.0  ...                 1.0   \n",
            "4                 1.0  ...                 1.0   \n",
            "5                 1.0  ...                 1.0   \n",
            "6                 1.0  ...                 1.0   \n",
            "7                 1.0  ...                 1.0   \n",
            "8                 1.0  ...                 1.0   \n",
            "9                 1.0  ...                 1.0   \n",
            "\n",
            "   E_PAGOMATRICULAPROPIO_Desconocido  E_PAGOMATRICULAPROPIO_No  \\\n",
            "0                                0.0                       1.0   \n",
            "1                                0.0                       1.0   \n",
            "2                                0.0                       1.0   \n",
            "3                                0.0                       1.0   \n",
            "4                                0.0                       1.0   \n",
            "5                                0.0                       1.0   \n",
            "6                                0.0                       0.0   \n",
            "7                                0.0                       0.0   \n",
            "8                                0.0                       0.0   \n",
            "9                                0.0                       0.0   \n",
            "\n",
            "   E_PAGOMATRICULAPROPIO_Si  PERIODO_ACADEMICO  INDICADOR_1  INDICADOR_2  \\\n",
            "0                       0.0           1.294094     0.437002    -0.556223   \n",
            "1                       0.0           1.294094     0.346934    -0.481341   \n",
            "2                       0.0           0.439801     0.232301    -0.492038   \n",
            "3                       0.0          -0.319570     1.771650    -0.941332   \n",
            "4                       0.0           1.294094     0.387874    -0.299484   \n",
            "5                       0.0           0.439801     2.328436    -1.262255   \n",
            "6                       1.0          -1.458627    -0.218040     0.417246   \n",
            "7                       1.0          -1.458627    -0.250792     0.599102   \n",
            "8                       1.0           1.294094    -0.995902     1.572571   \n",
            "9                       1.0          -1.458627     2.181051    -1.476204   \n",
            "\n",
            "   INDICADOR_3  INDICADOR_4  RENDIMIENTO_GLOBAL  \n",
            "0     0.813978     0.060296          medio-alto  \n",
            "1     0.508180     0.016142                bajo  \n",
            "2     0.729034     0.016142                bajo  \n",
            "3    -0.171371    -1.072993                alto  \n",
            "4     0.389259     0.457683          medio-bajo  \n",
            "5    -0.239326    -1.293764          medio-alto  \n",
            "6     0.083461     0.663736                alto  \n",
            "7     0.406247     0.398811          medio-bajo  \n",
            "8    -0.850922     0.958097          medio-bajo  \n",
            "9    -0.086427    -1.411508                alto  \n",
            "\n",
            "[10 rows x 28 columns]\n"
          ]
        }
      ],
      "source": [
        "processed_df = export_transformed_dataset(load_dataset(), FeatureConfig.from_dataframe(load_dataset()))\n",
        "print(processed_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-92TxbYyOqn"
      },
      "source": [
        "## Evaluación con un modelo preliminar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cZlr2ImSx7_Y"
      },
      "outputs": [],
      "source": [
        "def make_model_pipeline(config: FeatureConfig, random_state: int = SEED) -> Pipeline:\n",
        "    estimator = HistGradientBoostingClassifier(\n",
        "        random_state=random_state,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.12,\n",
        "        l2_regularization=0.0,\n",
        "    )\n",
        "    preprocessing = make_preprocessor(config, random_state=random_state)\n",
        "    model_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"features\", preprocessing),\n",
        "            (\"model\", estimator),\n",
        "        ]\n",
        "    )\n",
        "    return model_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-OWCoZhLyYCe"
      },
      "outputs": [],
      "source": [
        "def stratified_sample(df: pd.DataFrame, per_class: int, random_state: int = SEED) -> pd.DataFrame:\n",
        "    return df.groupby(TARGET_COLUMN, group_keys=False).sample(\n",
        "        n=min(per_class, df.groupby(TARGET_COLUMN).size().min()),\n",
        "        random_state=random_state,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RKOR2tAEylYX"
      },
      "outputs": [],
      "source": [
        "def evaluate_pipeline(\n",
        "    df: pd.DataFrame,\n",
        "    config: FeatureConfig,\n",
        "    sample_per_class: Optional[int] = 5000,\n",
        "    cv_splits: int = 3,\n",
        "    random_state: int = SEED,\n",
        "):\n",
        "    if sample_per_class is not None:\n",
        "        # Usando un sample (más liviano)\n",
        "        df_evaluation = stratified_sample(df, per_class=sample_per_class, random_state=random_state)\n",
        "    else:\n",
        "        # Usar todo el dataset\n",
        "        df_evaluation = df\n",
        "\n",
        "    X = df_evaluation.drop(columns=[TARGET_COLUMN] + config.drop, errors=\"ignore\")\n",
        "    y = df_evaluation[TARGET_COLUMN]\n",
        "\n",
        "    pipeline = make_model_pipeline(config, random_state=random_state)\n",
        "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
        "    scores = cross_val_score(pipeline, X, y, scoring=\"accuracy\", cv=cv, n_jobs=1)\n",
        "\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=random_state, stratify=y\n",
        "    )\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_valid)\n",
        "\n",
        "    evaluation = {\n",
        "        \"cv_scores\": scores.tolist(),\n",
        "        \"cv_mean\": float(scores.mean()),\n",
        "        \"holdout_accuracy\": float(accuracy_score(y_valid, y_pred)),\n",
        "        \"holdout_report\": classification_report(y_valid, y_pred, output_dict=True),\n",
        "    }\n",
        "\n",
        "    return evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rviu4aa_vmoN",
        "outputId": "d2d6caa0-c312-433a-91bf-ff1a3f865ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'cv_scores': [0.428896956254278, 0.4272829274843718, 0.427841773056712], 'cv_mean': 0.4280072189317872, 'holdout_accuracy': 0.4292129963898917, 'holdout_report': {'alto': {'precision': 0.5395825128003151, 'recall': 0.6240747067532172, 'f1-score': 0.5787611554100438, 'support': 35124.0}, 'bajo': {'precision': 0.4500742432895488, 'recall': 0.5694713414457901, 'f1-score': 0.5027816056754963, 'support': 34597.0}, 'medio-alto': {'precision': 0.3246186551299743, 'recall': 0.2535834984267568, 'f1-score': 0.2847375566350982, 'support': 34324.0}, 'medio-bajo': {'precision': 0.33421284080914687, 'recall': 0.26469307792773183, 'f1-score': 0.2954181040765755, 'support': 34455.0}, 'accuracy': 0.4292129963898917, 'macro avg': {'precision': 0.4121220630072463, 'recall': 0.42795565613837405, 'f1-score': 0.4154246054493035, 'support': 138500.0}, 'weighted avg': {'precision': 0.4128594146097269, 'recall': 0.4292129963898917, 'f1-score': 0.4164267487659137, 'support': 138500.0}}}\n"
          ]
        }
      ],
      "source": [
        "evaluation = evaluate_pipeline(load_dataset(), FeatureConfig.from_dataframe(load_dataset()), sample_per_class=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJphT3gH1IYG",
        "outputId": "18295376-4048-48fd-a8f5-4f52763a3254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"cv_scores\": [\n",
            "        0.428896956254278,\n",
            "        0.4272829274843718,\n",
            "        0.427841773056712\n",
            "    ],\n",
            "    \"cv_mean\": 0.4280072189317872,\n",
            "    \"holdout_accuracy\": 0.4292129963898917,\n",
            "    \"holdout_report\": {\n",
            "        \"alto\": {\n",
            "            \"precision\": 0.5395825128003151,\n",
            "            \"recall\": 0.6240747067532172,\n",
            "            \"f1-score\": 0.5787611554100438,\n",
            "            \"support\": 35124.0\n",
            "        },\n",
            "        \"bajo\": {\n",
            "            \"precision\": 0.4500742432895488,\n",
            "            \"recall\": 0.5694713414457901,\n",
            "            \"f1-score\": 0.5027816056754963,\n",
            "            \"support\": 34597.0\n",
            "        },\n",
            "        \"medio-alto\": {\n",
            "            \"precision\": 0.3246186551299743,\n",
            "            \"recall\": 0.2535834984267568,\n",
            "            \"f1-score\": 0.2847375566350982,\n",
            "            \"support\": 34324.0\n",
            "        },\n",
            "        \"medio-bajo\": {\n",
            "            \"precision\": 0.33421284080914687,\n",
            "            \"recall\": 0.26469307792773183,\n",
            "            \"f1-score\": 0.2954181040765755,\n",
            "            \"support\": 34455.0\n",
            "        },\n",
            "        \"accuracy\": 0.4292129963898917,\n",
            "        \"macro avg\": {\n",
            "            \"precision\": 0.4121220630072463,\n",
            "            \"recall\": 0.42795565613837405,\n",
            "            \"f1-score\": 0.4154246054493035,\n",
            "            \"support\": 138500.0\n",
            "        },\n",
            "        \"weighted avg\": {\n",
            "            \"precision\": 0.4128594146097269,\n",
            "            \"recall\": 0.4292129963898917,\n",
            "            \"f1-score\": 0.4164267487659137,\n",
            "            \"support\": 138500.0\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(json.dumps(evaluation, indent=4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
