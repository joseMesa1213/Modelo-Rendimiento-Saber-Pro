{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40dc93b4",
   "metadata": {},
   "source": [
    "# Modelo FT-Transformer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e3fa6",
   "metadata": {},
   "source": [
    "## Instalación de dependencias e imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610fd815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias necesarias (ejecutar una vez por sesión de Colab T4)\n",
    "!pip install -q torch optuna seaborn kaggle category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VARIABLES DE PREPROCESAMIENTO ===\n",
    "TARGET_COL = \"RENDIMIENTO_GLOBAL\"\n",
    "\n",
    "DROP_CANDIDATES = [\n",
    "    \"ID\",\n",
    "    \"F_TIENEINTERNET.1\",\n",
    "    \"E_PRIVADO_LIBERTAD\",\n",
    "]\n",
    "\n",
    "HIGH_CARDINALITY = [\n",
    "    \"E_PRGM_ACADEMICO\",\n",
    "    \"E_PRGM_DEPARTAMENTO\",\n",
    "]\n",
    "\n",
    "LOW_CARDINALITY = [\n",
    "    \"F_TIENEINTERNET\",\n",
    "    \"F_TIENECOMPUTADOR\",\n",
    "    \"F_TIENEAUTOMOVIL\",\n",
    "    \"F_TIENELAVADORA\",\n",
    "    \"E_PAGOMATRICULAPROPIO\",\n",
    "]\n",
    "\n",
    "ORDINAL_MAP = {\n",
    "    \"F_ESTRATOVIVIENDA\": [\n",
    "        \"Desconocido\",\n",
    "        \"Sin Estrato\",\n",
    "        \"Estrato 1\",\n",
    "        \"Estrato 2\",\n",
    "        \"Estrato 3\",\n",
    "        \"Estrato 4\",\n",
    "        \"Estrato 5\",\n",
    "        \"Estrato 6\",\n",
    "    ],\n",
    "    \"E_HORASSEMANATRABAJA\": [\n",
    "        \"Desconocido\",\n",
    "        \"0\",\n",
    "        \"Menos de 10 horas\",\n",
    "        \"Entre 11 y 20 horas\",\n",
    "        \"Entre 21 y 30 horas\",\n",
    "        \"Más de 30 horas\",\n",
    "    ],\n",
    "    \"E_VALORMATRICULAUNIVERSIDAD\": [\n",
    "        \"Desconocido\",\n",
    "        \"No pagó matrícula\",\n",
    "        \"Menos de 500 mil\",\n",
    "        \"Entre 500 mil y menos de 1 millón\",\n",
    "        \"Entre 1 millón y menos de 2.5 millones\",\n",
    "        \"Entre 2.5 millones y menos de 4 millones\",\n",
    "        \"Entre 4 millones y menos de 5.5 millones\",\n",
    "        \"Entre 5.5 millones y menos de 7 millones\",\n",
    "        \"Más de 7 millones\",\n",
    "    ],\n",
    "    \"F_EDUCACIONPADRE\": [\n",
    "        \"Desconocido\",\n",
    "        \"Ninguno\",\n",
    "        \"Primaria incompleta\",\n",
    "        \"Primaria completa\",\n",
    "        \"Secundaria (Bachillerato) incompleta\",\n",
    "        \"Secundaria (Bachillerato) completa\",\n",
    "        \"Técnica o tecnológica incompleta\",\n",
    "        \"Técnica o tecnológica completa\",\n",
    "        \"Educación profesional incompleta\",\n",
    "        \"Educación profesional completa\",\n",
    "        \"Postgrado\",\n",
    "        \"No Aplica\",\n",
    "        \"No sabe\",\n",
    "    ],\n",
    "    \"F_EDUCACIONMADRE\": [\n",
    "        \"Desconocido\",\n",
    "        \"Ninguno\",\n",
    "        \"Primaria incompleta\",\n",
    "        \"Primaria completa\",\n",
    "        \"Secundaria (Bachillerato) incompleta\",\n",
    "        \"Secundaria (Bachillerato) completa\",\n",
    "        \"Técnica o tecnológica incompleta\",\n",
    "        \"Técnica o tecnológica completa\",\n",
    "        \"Educación profesional incompleta\",\n",
    "        \"Educación profesional completa\",\n",
    "        \"Postgrado\",\n",
    "        \"No Aplica\",\n",
    "        \"No sabe\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "NUMERIC_COLUMNS = [\n",
    "    \"PERIODO_ACADEMICO\",\n",
    "    \"INDICADOR_1\",\n",
    "    \"INDICADOR_2\",\n",
    "    \"INDICADOR_3\",\n",
    "    \"INDICADOR_4\",\n",
    "]\n",
    "\n",
    "CLASS_NAMES = [\"alto\", \"medio-alto\", \"medio-bajo\", \"bajo\"]\n",
    "CLASS2IDX = {cls: idx for idx, cls in enumerate(CLASS_NAMES)}\n",
    "IDX2CLASS = {idx: cls for cls, idx in CLASS2IDX.items()}\n",
    "\n",
    "VAL_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "ARTIFACT_DIR = Path(\"./artifacts_ft_transformer\")\n",
    "ARTIFACT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device hint: {device} | Artifacts: {ARTIFACT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7259ef66",
   "metadata": {},
   "source": [
    "## Creación del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712700ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \".\"\n",
    "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n",
    "!unzip -q udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca548a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(path, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b0d01c",
   "metadata": {},
   "source": [
    "## Pipeline de Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7067328a",
   "metadata": {},
   "source": [
    "### Clases Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92155d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameImputer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Rellenar datos faltantes manteniendo la estructura DataFrame.\"\"\"\n",
    "\n",
    "    def __init__(self, fill_value: str = \"Desconocido\") -> None:\n",
    "        self.fill_value = fill_value\n",
    "        self.columns_: Optional[List[str]] = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: Optional[pd.Series] = None) -> \"DataFrameImputer\":\n",
    "        self.columns_ = list(X.columns) if hasattr(X, \"columns\") else None\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.columns_ is None:\n",
    "            raise RuntimeError(\"Se debe llamar fit antes de transform.\")\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.columns_)\n",
    "        return X.fillna(self.fill_value)\n",
    "\n",
    "    def get_feature_names_out(self, input_features: Optional[List[str]] = None) -> np.ndarray:\n",
    "        if input_features is not None:\n",
    "            return np.asarray(input_features, dtype=object)\n",
    "        if self.columns_ is None:\n",
    "            raise RuntimeError(\"Llamar fit antes de solicitar los nombres.\")\n",
    "        return np.asarray(self.columns_, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureConfig:\n",
    "    drop: List[str]\n",
    "    high_card: List[str]\n",
    "    low_card: List[str]\n",
    "    ordinal: List[str]\n",
    "    numeric: List[str]\n",
    "    ordinal_categories: List[List[str]]\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df: pd.DataFrame) -> \"FeatureConfig\":\n",
    "        available_columns = set(df.columns)\n",
    "        drop = [c for c in DROP_CANDIDATES if c in available_columns]\n",
    "        usable = available_columns - {TARGET_COL}\n",
    "        high_card = [c for c in HIGH_CARDINALITY if c in usable]\n",
    "        low_card = [c for c in LOW_CARDINALITY if c in usable]\n",
    "        ordinal = [c for c in ORDINAL_MAP if c in usable]\n",
    "        numeric = [c for c in NUMERIC_COLUMNS if c in usable]\n",
    "        ordinal_categories = [ORDINAL_MAP[c] for c in ordinal]\n",
    "        return cls(drop, high_card, low_card, ordinal, numeric, ordinal_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dfdac4",
   "metadata": {},
   "source": [
    "### Construcción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177747bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(config: FeatureConfig, random_state: int = RANDOM_STATE) -> Pipeline:\n",
    "    transformers = []\n",
    "\n",
    "    if config.high_card:\n",
    "        high_card_pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", DataFrameImputer(fill_value=\"Desconocido\")),\n",
    "                (\n",
    "                    \"encoder\",\n",
    "                    TargetEncoder(\n",
    "                        cols=config.high_card,\n",
    "                        smoothing=0.5,\n",
    "                        handle_unknown=\"value\",\n",
    "                        handle_missing=\"value\",\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        transformers.append((\"high_card\", high_card_pipeline, config.high_card))\n",
    "\n",
    "    if config.ordinal:\n",
    "        ordinal_pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Desconocido\")),\n",
    "                (\n",
    "                    \"encoder\",\n",
    "                    OrdinalEncoder(\n",
    "                        categories=config.ordinal_categories,\n",
    "                        dtype=float,\n",
    "                        handle_unknown=\"use_encoded_value\",\n",
    "                        unknown_value=-1,\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        transformers.append((\"ordinal\", ordinal_pipeline, config.ordinal))\n",
    "\n",
    "    if config.low_card:\n",
    "        low_card_pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Desconocido\")),\n",
    "                (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "            ]\n",
    "        )\n",
    "        transformers.append((\"one_hot\", low_card_pipeline, config.low_card))\n",
    "\n",
    "    if config.numeric:\n",
    "        numeric_pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "            ]\n",
    "        )\n",
    "        transformers.append((\"numeric\", numeric_pipeline, config.numeric))\n",
    "\n",
    "    column_transformer = ColumnTransformer(\n",
    "        transformers=transformers,\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "\n",
    "    preprocessing_pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", column_transformer),\n",
    "            (\"variance\", VarianceThreshold(threshold=1e-5)),\n",
    "        ]\n",
    "    )\n",
    "    return preprocessing_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8606929",
   "metadata": {},
   "source": [
    "### Procesar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55406dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    config: FeatureConfig,\n",
    "    random_state: int = RANDOM_STATE,\n",
    ") -> pd.DataFrame:\n",
    "    X = df.drop(columns=[TARGET_COL] + config.drop, errors=\"ignore\")\n",
    "    y = df[TARGET_COL]\n",
    "\n",
    "    preprocessing = make_preprocessor(config, random_state=random_state)\n",
    "    preprocessing.fit(X, y)\n",
    "\n",
    "    feature_names = preprocessing.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "    mask = preprocessing.named_steps[\"variance\"].get_support()\n",
    "    selected_feature_names = feature_names[mask]\n",
    "    transformed = preprocessing.transform(X)\n",
    "\n",
    "    processed_df = pd.DataFrame(transformed, columns=selected_feature_names, index=df.index)\n",
    "    processed_df[TARGET_COL] = y.values\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e85c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = load_dataset(Path(\"train.csv\"))\n",
    "train_config = FeatureConfig.from_dataframe(train_raw)\n",
    "train_df = process_dataset(train_raw, train_config)\n",
    "print(f\"train_df shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b47541b",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f2db2a",
   "metadata": {},
   "source": [
    "### Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcde94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_fold_metrics(name: str, fold_scores: List[dict]) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(fold_scores)\n",
    "    summary = {\n",
    "        \"model\": name,\n",
    "        \"mean_acc\": df[\"accuracy\"].mean(),\n",
    "        \"std_acc\": df[\"accuracy\"].std(ddof=0),\n",
    "        \"min_acc\": df[\"accuracy\"].min(),\n",
    "        \"max_acc\": df[\"accuracy\"].max(),\n",
    "    }\n",
    "    return df, summary\n",
    "\n",
    "\n",
    "def describe_class_balance(labels: np.ndarray):\n",
    "    counts = pd.Series(labels).value_counts().sort_index()\n",
    "    display(counts.rename(index=IDX2CLASS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9798a8",
   "metadata": {},
   "source": [
    "### Partición estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape: {train_df.shape} | Memoria ~{train_df.memory_usage().sum() / 1e6:.1f} MB\")\n",
    "\n",
    "y = train_df[TARGET_COL].map(CLASS2IDX).to_numpy(dtype=np.int64)\n",
    "X = train_df.drop(columns=[TARGET_COL]).to_numpy(dtype=np.float32)\n",
    "\n",
    "describe_class_balance(y)\n",
    "feature_dim = X.shape[1]\n",
    "print(f\"Dimensionalidad final: {feature_dim}\")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=VAL_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y,\n",
    "    shuffle=True,\n",
    " )\n",
    "print(\n",
    "    f\"Split -> train: {X_train.shape[0]} muestras | valid: {X_valid.shape[0]} muestras\",\n",
    " )\n",
    "\n",
    "del train_df\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae7a6b",
   "metadata": {},
   "source": [
    "### Configuración del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_config = {\n",
    "    \"d_token\": 64,\n",
    "    \"n_blocks\": 4,\n",
    "    \"n_heads\": 8,\n",
    "    \"dropout\": 0.2,\n",
    "    \"ffn_factor\": 2.0,\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"warmup_epochs\": 2,\n",
    "    \"grad_clip\": 1.0,\n",
    "}\n",
    "\n",
    "ft_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c3a7e5",
   "metadata": {},
   "source": [
    "### Arquitectura FT-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, features: np.ndarray, labels: np.ndarray):\n",
    "        self.features = torch.from_numpy(features.astype(np.float32, copy=False))\n",
    "        self.labels = torch.from_numpy(labels.astype(np.int64, copy=False))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class NumericalFeatureTokenizer(nn.Module):\n",
    "    def __init__(self, n_features: int, d_token: int) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(n_features, d_token) * 0.02)\n",
    "        self.bias = nn.Parameter(torch.zeros(n_features, d_token))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x shape: (batch, features) -> output (batch, features, d_token)\n",
    "        x = x.unsqueeze(-1)\n",
    "        return x * self.weight + self.bias\n",
    "\n",
    "\n",
    "class FTTransformer(nn.Module):\n",
    "    def __init__(self, n_features: int, n_classes: int, config: Dict[str, float]):\n",
    "        super().__init__()\n",
    "        d_token = config[\"d_token\"]\n",
    "        self.tokenizer = NumericalFeatureTokenizer(n_features, d_token)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_token))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_token,\n",
    "            nhead=config[\"n_heads\"],\n",
    "            dim_feedforward=int(d_token * config[\"ffn_factor\"] * 2),\n",
    "            dropout=config[\"dropout\"],\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\",\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config[\"n_blocks\"])\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "        self.head = nn.Sequential(nn.LayerNorm(d_token), nn.Linear(d_token, n_classes))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        tokens = self.tokenizer(x)\n",
    "        cls = self.cls_token.expand(tokens.size(0), -1, -1)\n",
    "        x = torch.cat([cls, tokens], dim=1)\n",
    "        encoded = self.encoder(self.dropout(x))\n",
    "        logits = self.head(encoded[:, 0])\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb77916",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc16ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    grad_clip: float,\n",
    " ) -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        if grad_clip > 0:\n",
    "            # Este clip suave evita explosiones en los primeros pasos\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        total_correct += (logits.argmax(dim=1) == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, criterion: nn.Module) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        total_correct += (logits.argmax(dim=1) == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "\n",
    "def build_scheduler(optimizer: torch.optim.Optimizer, warmup_epochs: int):\n",
    "    if warmup_epochs <= 0:\n",
    "        return None\n",
    "\n",
    "    def lr_lambda(epoch: int):\n",
    "        # Calentamos el LR para estabilizar transformers pequeños\n",
    "        return min(1.0, (epoch + 1) / warmup_epochs)\n",
    "\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "\n",
    "def train_ft_transformer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_valid: np.ndarray,\n",
    "    y_valid: np.ndarray,\n",
    "    config: Dict[str, float],\n",
    " ) -> Tuple[nn.Module, List[dict]]:\n",
    "    # Dataloader simple porque todo ya está numerizado\n",
    "    train_loader = DataLoader(\n",
    "        TabularDataset(X_train, y_train),\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        TabularDataset(X_valid, y_valid),\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    model = FTTransformer(feature_dim, len(CLASS_NAMES), config).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "    )\n",
    "    scheduler = build_scheduler(optimizer, config.get(\"warmup_epochs\", 0))\n",
    "\n",
    "    history = []\n",
    "    best_state = None\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, config[\"epochs\"] + 1):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, config[\"grad_clip\"]\n",
    "        )\n",
    "        val_loss, val_acc = evaluate(model, valid_loader, criterion)\n",
    "        if scheduler is not None and epoch <= config.get(\"warmup_epochs\", 0):\n",
    "            scheduler.step()\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            # Guardamos el checkpoint más estable para inferencia\n",
    "            best_acc = val_acc\n",
    "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "        history.append(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_acc\": val_acc,\n",
    "                \"lr\": optimizer.param_groups[0][\"lr\"],\n",
    "            }\n",
    "        )\n",
    "        # El print rápido ayuda al monitoreo en Colab\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} acc={train_acc:.4f} | \"\n",
    "            f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\",\n",
    "        )\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2740f346",
   "metadata": {},
   "source": [
    "### Ejecución del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a03f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model, training_history = train_ft_transformer(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    ft_config,\n",
    " )\n",
    "history_df = pd.DataFrame(training_history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acca21f",
   "metadata": {},
   "source": [
    "### Evaluación en validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = ft_model(torch.from_numpy(X_valid).to(device)).cpu().numpy()\n",
    "\n",
    "y_pred = logits.argmax(axis=1)\n",
    "val_acc = accuracy_score(y_valid, y_pred)\n",
    "print(f\"Accuracy validación: {val_acc:.4f}\")\n",
    "\n",
    "conf_mat = confusion_matrix(y_valid, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    conf_mat,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=CLASS_NAMES,\n",
    "    yticklabels=CLASS_NAMES,\n",
    " )\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de confusión FT-Transformer\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_valid, y_pred, target_names=CLASS_NAMES))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "10pfwrHuvl7mjlQt1C5Vu4efRPGgEkjDU",
     "timestamp": 1764165750668
    }
   ]
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
